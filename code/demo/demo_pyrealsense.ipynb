{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyrealsense2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/sangbeom/kinematics-usage/code/demo/demo_pyrealsense.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B163.152.162.94/home/sangbeom/kinematics-usage/code/demo/demo_pyrealsense.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpyrealsense2\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mrs\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B163.152.162.94/home/sangbeom/kinematics-usage/code/demo/demo_pyrealsense.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B163.152.162.94/home/sangbeom/kinematics-usage/code/demo/demo_pyrealsense.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcv2\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyrealsense2'"
     ]
    }
   ],
   "source": [
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class RealsenseCamera:\n",
    "    def __init__(self):\n",
    "        # Configure depth and color streams\n",
    "        print(\"Loading Intel Realsense Camera\")\n",
    "        self.pipeline = rs.pipeline()\n",
    "\n",
    "        config = rs.config()\n",
    "        config.enable_stream(rs.stream.color, 1280, 720, rs.format.bgr8, 30)\n",
    "        config.enable_stream(rs.stream.depth, 1280, 720, rs.format.z16, 30)\n",
    "\n",
    "        # Start streaming\n",
    "        self.pipeline.start(config)\n",
    "        align_to = rs.stream.color\n",
    "        self.align = rs.align(align_to)\n",
    "\n",
    "\n",
    "    def get_frame_stream(self):\n",
    "        # Wait for a coherent pair of frames: depth and color\n",
    "        frames = self.pipeline.wait_for_frames()\n",
    "        aligned_frames = self.align.process(frames)\n",
    "        depth_frame = aligned_frames.get_depth_frame()\n",
    "        color_frame = aligned_frames.get_color_frame()\n",
    "\n",
    "        if not depth_frame or not color_frame:\n",
    "            # If there is no frame, probably camera not connected, return False\n",
    "            print(\"Error, impossible to get the frame, make sure that the Intel Realsense camera is correctly connected\")\n",
    "            return False, None, None\n",
    "\n",
    "        # Apply filter to fill the Holes in the depth image\n",
    "        spatial = rs.spatial_filter()\n",
    "        spatial.set_option(rs.option.holes_fill, 3)\n",
    "        filtered_depth = spatial.process(depth_frame)\n",
    "\n",
    "        hole_filling = rs.hole_filling_filter()\n",
    "        filled_depth = hole_filling.process(filtered_depth)\n",
    "\n",
    "\n",
    "        # Create colormap to show the depth of the Objects\n",
    "        colorizer = rs.colorizer()\n",
    "        depth_colormap = np.asanyarray(colorizer.colorize(filled_depth).get_data())\n",
    "\n",
    "\n",
    "        # Convert images to numpy arrays\n",
    "        # distance = depth_frame.get_distance(int(50),int(50))\n",
    "        # print(\"distance\", distance)\n",
    "        depth_image = np.asanyarray(filled_depth.get_data())\n",
    "        color_image = np.asanyarray(color_frame.get_data())\n",
    "\n",
    "        depth_colormap_dim = depth_colormap.shape\n",
    "        color_colormap_dim = color_image.shape\n",
    "\n",
    "        # If depth and color resolutions are different, resize color image to match depth image for display\n",
    "        if depth_colormap_dim != color_colormap_dim:\n",
    "            resized_color_image = cv2.resize(color_image, dsize=(depth_colormap_dim[1], depth_colormap_dim[0]), interpolation=cv2.INTER_AREA)\n",
    "            images = np.hstack((resized_color_image, depth_colormap))\n",
    "        else:\n",
    "            images = np.hstack((color_image, depth_colormap))\n",
    "\n",
    "        # Show images\n",
    "        # cv2.namedWindow('RealSense', cv2.WINDOW_AUTOSIZE)\n",
    "        # cv2.imshow('RealSense', images)\n",
    "        # cv2.waitKey(1)\n",
    "\n",
    "        # cv2.destroyAllWindows()\n",
    "        return True, color_image, depth_image, depth_colormap\n",
    "\n",
    "    def release(self):\n",
    "        self.pipeline.stop()\n",
    "        #print(depth_image)\n",
    "\n",
    "        # Apply colormap on depth image (image must be converted to 8-bit per pixel first)\n",
    "        #depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.10), 2)\n",
    "\n",
    "        # Stack both images horizontally\n",
    "\n",
    "        #images = np.hstack((color_image, depth_colormap))\n",
    "\n",
    "def image_capture(img_path, depth_path):\n",
    "    real = RealsenseCamera()\n",
    "    while True:\n",
    "        ret, bgr_frame, depth_frame, depth_colormap = real.get_frame_stream()\n",
    "\n",
    "        cv2.imshow(\"depth frame\", depth_frame)\n",
    "        cv2.imshow(\"Bgr frame\", bgr_frame)\n",
    "\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == 27:\n",
    "            break\n",
    "        elif key == ord('s'): # wait for 's' key to save and exit\n",
    "            cv2.imwrite(img_path, bgr_frame)\n",
    "            np.save(depth_path , depth_frame)\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "\n",
    "    real.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "def plot(img, depth, cx, cy):\n",
    "    IMG = cv2.imread(img, cv2.IMREAD_COLOR)\n",
    "    DEPTH = np.load(depth)\n",
    "    cv2.imshow(\"depth frame\", DEPTH)\n",
    "    cv2.imshow(\"Bgr frame\", IMG)\n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        break\n",
    "    cv2.destroyAllWindows()\n",
    "    print(DEPTH[cy,cx])\n",
    "\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    img_path = './data/img.png'\n",
    "    depth_path = './data/depth.npy'\n",
    "    # image_capture(img_path, depth_path)\n",
    "    plot(img_path, depth_path, 672, 313)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
